---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

set.seed(1234)
```

# rollout

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![CRAN status](https://www.r-pkg.org/badges/version/rollout)](https://CRAN.R-project.org/package=rollout)
[![R-CMD-check](https://github.com/iancero/rollout/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/iancero/rollout/actions/workflows/R-CMD-check.yaml)
[![Codecov test coverage](https://codecov.io/gh/iancero/rollout/graph/badge.svg)](https://app.codecov.io/gh/iancero/rollout)
<!-- badges: end -->


## Basic Example

We begin with a basic example of the most widely known rollout trial format: a stepped wedge trial. In such a trial, sites are randomly assigned to cohorts. Then, these cohorts are assigned to receive the intervention beginning at different times. Data are recorded for the duration of the study, both before (baseline condition) and after the initiation of an intervention condition. 

In `rollout`, simulating such a trial begins with a matrix specification of the cohorts and their transition points, like so.

```{r}
library(tidyverse)

rollout_schedule <- tribble(
  ~cohort, ~site, ~t1,    ~t2,    ~t3,    ~t4,    ~t5,
  "c1",    "001", "bsln", "intv", "intv", "intv", "intv",
  "c1",    "002", "bsln", "intv", "intv", "intv", "intv",
  "c2",    "003", "bsln", "bsln", "intv", "intv", "intv",
  "c2",    "004", "bsln", "bsln", "intv", "intv", "intv",
  "c3",    "005", "bsln", "bsln", "bsln", "intv", "intv",
  "c3",    "006", "bsln", "bsln", "bsln", "intv", "intv",
  "c4",    "007", "bsln", "bsln", "bsln", "bsln", "intv",
  "c4",    "008", "bsln", "bsln", "bsln", "bsln", "intv"
)
```

This allows the user maximum control over what can become a complex process of scheduling, responding to real world pragmatic constraints. But in this format, it is not yet convenient for simulation, so `rollout` offers the utility function `pivot_schedule_longer()`.

```{r}
library(rollout)

rollout_design <- rollout_schedule |> 
  pivot_schedule_longer(t1:t5)

head(rollout_design)
```

In addition to performing a wide-to-long pivot on our schedule, this function has also computed two time columns: chron_time and local_time (0-indexed, to make cohort-specific effects easier to program). It has also constructed a condition column of all the conditions.

Now that the data are in this format, the user is prepared to incoporate any site-level background information they might have. For example, as part of pre-trial assessment and coordination with the study sites, a user might have access to site-level information, like the self-reported readiness to receive the intervention at the site, as well as the relative population of observational units at the site (e.g., classes per timepoint, servicemembers per class). For simplicity, we imagine some of these data below.

```{r}
site_info <- tribble(
  ~site, ~admin_readiness, ~classes_per_time, ~members_per_class,
  "001",    6,                11,                23,
  "002",    7,                15,                25,
  "003",    6,                11,                22,
  "004",    9,                12,                16,
  "005",    7,                11,                24,
  "006",    2,                9,                 22,
  "007",    2,                9,                 16,
  "008",    7,                14,                25,
)
```

And then link them to our design dataframe. We can do this with a simple left_join(), but we are stuck with the fact that two of our columns are actually counts of observational units (in fact, nested units), which will need to be expanded too. Anticipating this is a common situation, `rollout` has its own helper function for joining and expanding such site-related information:


```{r}
rollout_design <- rollout_design |> 
  join_info(
    site_info,
    by = "site",
    uncount_vars = c("classes_per_time", "members_per_class"),
    .ids = c("class", "member")
  )
```

```{r}
# TODO: add parameter combination step to design df process

rollout_design <- rollout_design |> 
  add_params(
    
  )
  expand_grid(
    effect_size = c(.10, .20, .30),
    sample_size = c(1000, 2000, 3000)
  )

```



With our design fully expanded, we now need to initialize several replicates of this same dataset for later simulation of data.

```{r}
simulated_trials <- rollout_design |> 
  initialize_replicates(n = 100)

head(simulated_trials)
```

### Simulating effects

#### Fixed effects

To start, let's add an intervention effect that gives an immediate boost in individual-level outcomes, followed by slow further improvement. We'll also add an effect representing a potential confound - a global improvement in the overall population (what an economist might call a "secular trend").

```{r}
library(tictoc)

tic() # TODO: add in descriptions of how long the process took for how many replicates

simulated_trials <- simulated_trials |>
  add_fixed_effect(
    condition = case_when(
      condition == "bsln" ~ 0,
      condition == "intv" ~ .50 + effect_size*local_time)) |> 
  add_fixed_effect(
    popwide_decline = .10*chron_time)

toc()

# 2.25 sec elapsed for 100 replicates

head(simulated_trials)
```

```{r}
simulated_trials |>
  add_fixed_effect(
    .condition = case_when(
      condition == "bsln" ~ 0,
      condition == "intv" ~ .50 + my_params*local_time),
    .x
    )

```


Underneath the hood, `add_fixed_effect()` is a thin wrapper around `mutate()` that does a few things: first, it limits the number of variables that can be created in a single call to exactly one named argument. This admittedly creates some redundant work for the user, who now has to call `add_fixed_effect()` multiple times, but comes with the advantage of forcing more readable code for these designs. All effect generation functions (more on these below) in `rollout` follow this convention. Second, they pre-pend all effect variables with a "`.`" to make it obvious which variables in the `simulated_trials` dataframe are data and which are effects that will eventually be used in the generation of an outcome variable. In this way, the user can focus on data that they want the effect to be associated with, rather than keeping variable names straight. It also facilitates the creation of an outcome creation function, which can automatically search for effects in `simulated_trials` and aggregate them into an outcome.

#### Random effects

Random effects are simulated similarly to fixed effects, except that it is sometimes important to take nesting structure into account. For example, to create a class-level random intercept, we need to specify that classes are nested within sites and cohorts, like so:

```{r}
simulated_trials <- simulated_trials |>
  add_random_effect(
    instructor_experience = rnorm(n = 1, mean = 0, sd = .30),
    .nesting = c("cohort", "site", "class"))

head(simulated_trials)
```

As another example in this trial, it might also be important for even instances of a given class to share variance because they have overlapping students.

```{r}
simulated_trials <- simulated_trials |>
  add_random_effect(
    student_cohesion = rnorm(n = 1, mean = 0, sd = .20),
    .nesting = c("cohort", "site", "class", "local_time"))

head(simulated_trials)
```
Again, underneath the hood, this is a wrapper to some dplyr functions applying a groupby-mutate-ungroup pattern. However, it is slightly more complicated because it will intercept the existing group structure of the incoming dataframe (e.g., if group_by has been called before), store it, calculate the random effect according to the nesting structure (if specified), then regroup the dataframe exactly as it was before the function. If no nesting structure is specified, this function will simply rely on the grouping structure given to it in the incoming dataframe.

#### Error variance

Finally, the simplest effect to add is random error, which is simple enough to specify with just a variance.

```{r}
simulated_trials <- simulated_trials |>
  add_error(variance = .25)
```

### Outcome variables

We can add three different types of outcome variables: linear, binary (logistic), and Poisson. Unlike the effects above, these at NOT automatically prepended with "." because they are observed values - rather than effects, they are data. Additionally, both the binary and Poisson functions return multiple columns, including the final observed output column (i.e., the simulated binary outcome) and the associated input columns that were involved in producing it (i.e., y_linear, y_prob).

```{r}
simulated_trials <- simulated_trials |>
  add_binary_outcome()

head(simulated_trials)
```


```{r}
# fit_models_parallel <- function(data, .x, .f, ...) {
#   # Set up parallel backend
#   future::plan(future::multisession)
#   
#   # Get column name as string from the tidyselect-style input
#   col_name <- rlang::as_name(rlang::enquo(.x))
#   
#   # Get the number of datasets
#   n_datasets <- nrow(data)
#   
#   # Set up progress reporting
#   progressr::handlers(progressr::handler_progress(
#     format = "[:bar] :percent :eta",
#     clear = FALSE
#   ))
#   
#   # Create a quosure of the formula function
#   formula_fn <- rlang::enquo(.f)
#   
#   # Apply the model function to each dataset with progress
#   progressr::with_progress({
#     # Create a progressor function
#     p <- progressr::progressor(steps = n_datasets)
#     
#     result <- data %>%
#       dplyr::mutate(model = furrr::future_map(
#         .x = .data[[col_name]],
#         .f = function(d) {
#           # Apply the formula function
#           model_result <- rlang::eval_tidy(formula_fn, list(.x = d))
#           # Update progress
#           p()
#           # Return result
#           return(model_result)
#         },
#         ...
#       ))
#   })
#   
#   # Return the updated dataframe with models
#   return(result)
# }
# 
# fit_models_parallel <- function(data, .x, .f, ...) {
#   # Set up parallel backend
#   future::plan(future::multisession)
#   
#   # Get column name as string from the tidyselect-style input
#   col_name <- rlang::as_name(rlang::enquo(.x))
#   
#   # Get the number of datasets
#   n_datasets <- nrow(data)
#   
#   # Set up progress reporting
#   progressr::handlers(progressr::handler_progress(
#     format = "[:bar] :percent :eta",
#     clear = FALSE
#   ))
#   
#   # Get the actual function from the formula
#   model_fn <- rlang::as_function(rlang::enquo(.f))
#   
#   # Apply the model function to each dataset with progress
#   progressr::with_progress({
#     # Create a progressor function
#     p <- progressr::progressor(steps = n_datasets)
#     
#     result <- data %>%
#       dplyr::mutate(model = furrr::future_map(
#         .x = .data[[col_name]],
#         .f = function(d) {
#           # Apply the function to the dataset
#           model_result <- model_fn(d)
#           # Update progress
#           p()
#           # Return result
#           return(model_result)
#         },
#         ...
#       ))
#   })
#   
#   # Return the updated dataframe with models
#   return(result)
# }
# 
# nested_trials <- simulated_trials |> 
#   group_by(sample_id) |> 
#   nest() |> 
#   ungroup() |> 
#   slice(1:10) |> 
#   fit_models_parallel(
#     .x = data,
#     .f = ~lmer(y_linear ~ condition + (1 | cohort), data = .x)
#   )
```


```{r}
# library(tidyverse)
# library(furrr)
# 
# plan(multisession)
# 
# # Simulated nested data
# nested_data <- tibble(
#   id = 1:3,
#   data = map(id, ~ tibble(x = rnorm(100), y = rnorm(100)))
# )
# 
# # Fit model inline
# nested_data <- nested_data %>%
#   mutate(model = future_map(data, ~ lm(y ~ x, data = .x)))
# 
# # Check result
# summary(nested_data$model[[1]])

```

```{r}
# fit_models <- function(.data, .x, .f, ...) {
#   x_quo <- rlang::enquo(.x)
#   f_fn  <- rlang::as_function(.f)
# 
#   dplyr::mutate(.data, model = furrr::future_map(!!x_quo, f_fn, ...))
# }

# 
# fit_models <- function(.data, .x, .f, ..., .progress = FALSE) {
#   x_quo <- rlang::enquo(.x)
#   f_fn  <- rlang::as_function(.f)
# 
#   dplyr::mutate(
#     .data,
#     model = furrr::future_map(!!x_quo, f_fn, ..., .progress = .progress)
#   )
# }

# fit_models <- function(.data, .x, .f, ..., .progress = FALSE) {
#   x_quo <- rlang::enquo(.x)
#   f_fn  <- rlang::as_function(.f)
# 
#   if (.progress) {
#     progressr::with_progress({
#       dplyr::mutate(
#         .data,
#         model = furrr::future_map(!!x_quo, f_fn, ..., .progress = TRUE)
#       )
#     })
#   } else {
#     dplyr::mutate(
#       .data,
#       model = furrr::future_map(!!x_quo, f_fn, ..., .progress = FALSE)
#     )
#   }
# }


fit_models <- function(.data, .x, .f, ..., .progress = FALSE) {
  x_quo <- rlang::enquo(.x)
  f_fn  <- rlang::as_function(.f)

  run_map <- function() {
    dplyr::mutate(
      .data,
      model = furrr::future_map(!!x_quo, f_fn, ..., .progress = .progress)
    )
  }

  if (.progress) {
    progressr::with_progress(run_map())
  } else {
    run_map()
  }
}




# # ---------
# 
# future::plan(future::multisession)
# 
# progressr::handlers(progressr::handler_txtprogressbar)
# 
# 
# nested_data <- tibble::tibble(
#   id = 1:1000,
#   data = purrr::map(1:1000, ~ tibble::tibble(x = rnorm(100), y = rnorm(100)))
# )
# 
# nested_data <- fit_models(
#   nested_data,
#   .x = data,
#   .f = ~ lm(y ~ x, data = .x),
#   .progress = TRUE
# )
# 
# summary(nested_data$model[[1]])


```

```{r}
# future::plan(future::multisession)
# progressr::handlers(progressr::handler_rstudio)
# 
# 
# nested_data <- tibble::tibble(
#   id = 1:1000,
#   data = purrr::map(1:1000, ~ tibble::tibble(x = rnorm(100), y = rnorm(100)))
# )
# 
# progressr::with_progress({
#   nested_data2 <- furrr::future_map(
#     nested_data$data,
#     ~ lm(y ~ x, data = .x),
#     .progress = TRUE
#   )
# })

```

```{r}
# future::plan(future::multisession)
# progressr::handlers(progressr::handler_rstudio)  # for RStudio
# 
# x <- 1:100
# 
# progressr::with_progress({
#   y <- furrr::future_map(x, ~ Sys.sleep(0.01), .progress = TRUE)
# })
# 
# ```
# ```{r}
# progressr::handlers(progressr::handler_rstudio)  # once per session
# future::plan(future::multisession)
# 
# progressr::with_progress({
#   nested_data <- fit_models(
#     nested_data,
#     .x = data,
#     .f = ~ lm(y ~ x, data = .x),
#     .progress = TRUE
#   )
# })

```


```{r}
# progressr::handlers(progressr::handler_rstudio)  # once per session
# future::plan(future::multisession)
# 
# progressr::with_progress({
#   nested_data <- fit_models(
#     nested_data,
#     .x = data,
#     .f = ~ lm(y ~ x, data = .x),
#     .progress = TRUE
#   )
# })
```



```{r}
fit_models <- function(.data, .x, .f, ..., .progress = TRUE, .col = "model") {
  x_quo <- rlang::enquo(.x)
  f_fn  <- rlang::as_function(.f)
  input_list <- rlang::eval_tidy(x_quo, .data)

  # Choose parallel backend
  is_windows <- .Platform$OS.type == "windows"
  cores <- max(1L, parallel::detectCores() - 1L)

  # Parallel apply with progress bar
  if (is_windows) {
    cl <- parallel::makeCluster(cores)
    on.exit(parallel::stopCluster(cl), add = TRUE)

    result <- pbapply::pblapply(input_list, f_fn, ..., cl = cl)
  } else {
    options(mc.cores = cores)
    result <- pbapply::pblapply(input_list, f_fn, ...)
  }

  # Add result column
  dplyr::mutate(.data, !!.col := result)
}

library(pbapply)
library(parallel)
library(tibble)
library(purrr)
library(dplyr)
library(rlang)
library(tidyverse)

# example data
nested_data <- tibble(
  id = 1:1000,
  data = map(1:1000, ~ tibble(x = rnorm(100), y = .01*x + rnorm(100)))
)

nested_data <- nested_data |> 
  fit_models(
    .x = data,
    .f = ~ lm(y ~ x, data = .x))


nested_data |> 
  mutate(results = map(model, broom::tidy)) |> 
  unnest(results) |> 
  filter(term == 'x') |> 
  summarize(power = mean(p.value < .05)) # TODO: be ready to handle cases with NA and NaN

# Thinking through general output for summary functions

# We'll need to be able to fit a null model and find the cutoff value for that,
# then generate the next dataset

# Make sure to include the test statistic (not just p-value) in output

# We need to find a way to specify multiple sample size conditions / 

```



```{r}
nested_data 
```


```{r}
summarize_models = function (.data, model_col = 'model') {
  .data |> 
    mutate(model_results = map(.data[[model_col]], tidy)) |> 
    unnest(model_results) |> 
    filter(term == 'x') |> 
    summarize(power = mean(p.value < .05))
}

nested_data |> 
  summarize_models()
```




## Fitting models

```{r}
# Define fit function separately
my_fit <- function(df) lm(y_linear ~ condition, data = df)

nested_trials <- simulated_trials |> 
  group_by(sample_id) |> 
  nest() 

# Run the model fitting
setup_progress()
fit_models(nested_trials, fit_fun = my_fit, .parallel = FALSE)

```

```{r}
str(simulated_trials$data[[1]])
```



