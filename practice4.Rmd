---
title: "R Notebook"
---

# NOTE: for clarity, do fixed effects before random effects

# TODO (2024-06-14):

Start with generic version of specifying parameters
  - Model parameters
  - Population generating parameters
      - I want to change not just effect sizes, but also ICCs
  - Output parameters (what kinds of things do you want to see)
  - Replication-based parameters (how many?)

Next steps are entering parameters:
  - Model characteristics, what kind of model are you using (e.g., continuous outcome vs glmer)
  - Allow user to specify names of columns and units
  - Other parameters based on the simulations you want to do, how many replicates are you looking for
  - What are the **collections** of either effect sizes or selected power values that you want to look at
      - For every effect size, get a power
      - For every power, what is the minimal effect size that you could detect


- Have code that can generate data for this case:
  - [x] Conditions that are rolled out
      - [x] true / clean stepped wedge (baseline vs conversion to intervention)
      - everyone is measured at all times
      - [x] use a condition matrix as input
  - [x] 4 levels (cohort - where condition is assigned, clinic, patient, time)
      - specify numbers in nesting structure
      - [x] only things that change across time are patients (whatever their outcome variable is)
          - look at "reach" as the outcome variable for patients: what's the proportion of people screened positive, who eventually get treatment. Among positive screens, who actually gets into treatment
          - [x] generate a changing number of patients each time (poisson variable)
  - [x] With unbalanced / uneven group sizes (that the user can specify)


- Have a model together that generates random intercepts
- Generate a flow diagram or some pseudocode



- Assigment matrix
  Columns are timepoints
  Rows are the units who will be assigned (e)

- Specify the levels of the hierarchy
- which level of it is used for assignment (hospitals, doctors, etc)
- How many of the next lowest level are within each of the assigned level
- The level below that (e.g., patients) will generally not be the same at each timepoint (this is the denominator for something like reach)
    - So these get newly generated at each timepoint
    - So we'll need to specify the distribution with which they are generated
- For each condition over time, what does the numerator / improvement in the outcome look like? These are fixed effects (then we can add the distribution of errors here too)
- Somehow we need to include ICCs (patients within doctors, doctors within hospitals) - consider taking logs of the proportions to do things on a log scale

- Specifying what the fixed effects are and what their parameters are and how they work on the level of where the assignment occurs (everything else above and below should be random)

- Specify information about number of replications for the generated data. Is the model for analysis the same as the generating model?

- Using a standard binomial proportion variance (pq/n), we want that to be able to vary across situations. For example, MPLUS there is a random slope where the mean is 0, but the regression variance is some fixed quantity.
 
```{r}
library(tidyverse)

site_data_df <- site_data_ex # registered example site data to package

site_data_df <- site_data_df |> 
  rename(school = hospital, num_teachers = num_pcps)


sim_samples_df <- stepped_wedge_ex |> 
  pivot_schedule_longer(t1:t9) |> # added condition time
  join_unit_info(site_data_df, by = "cohort", uncount_unit = num_teachers, .id = "teacher") |> 
  initialize_replicates(n = 10)
```

# 2024-06-28

We have two items to work on now:
  1. How do we allow the parameters to vary (e.g., effect sizes, ICCs). Maybe we constrain users to have to change those manually?
  2. How do we calculate output-related content? We want to be able to calculate not just our own p-values, but also our own critical values (e.g., by computing the 95th percentiles of the observed test statistic across our empirical simulated distribution of samples).
       - For now, let's assume we're doing one analysis at a time and doing one replication. Let's keep track of a way to save each model's results so we can compare results from different models on the same dataset.
       - Allow ourselves to compare the results of LRT tests.
       - Calculate variance of random effect and do comparison where you fix that variance to zero and run a model comparing the two (with an LRT)
       - Overall, we want to have a convenient *labelling* of these objects to keep track of.
       
       
       
  3. Also, think of a way to capitalize on starting values to speed up lmer (but do this last)
  

```{r}
sim_samples_df |> 
  add_fixed_effect(condition = ifelse(condition == "intervention", 2 + .15*condition_time, 0)) |>
  add_random_effect(county >> school = 
                      ifelse(
                        condition == "intervention", 
                        yes = rnorm(n = 1, sd = 1), 
                        no = 0))




|>
  add_fixed_effect(teacher = ifelse(condition == "intervention", 2 + .15*condition_time, 0)) |>
  group_by(sim_sample, county, school) |> 
  add_random_intercept(variance = 1) |> 
  group_by(sim_sample, neighborhood, student) |> 
  add_random_intercept(variance = 1)

  add_random_intercept(variance = 1, nesting = c(school, teacher))
```




Maybe we have a seperate list or dataframe of all of the extraneous (but necessary) information about the simulation (e.g., the hierarchy of nested units, and where they fit in terms of the randomization - above, below, same). Another part is information about generating the numbers of the specific. Note example: patients get random assignment, physicians are fixed. 

# Input

Model specification: the characteristics of the outcome variable we are analyzing
Characteristics of what we want to get from the outcome - do we want to achieve 80% power?
Need a dataframe for random effects, are there ICCs to specify (or variances) - maybe in list form?
  - Think of how specify random effects, possibly dataframe vs empty, 
characteristics of missing data should also be a parameter you can add

# TODO: make these lines work

For the simulations, what are the values we are varying (make this as flexible as possible, behind the scenes these will cost us computing time). What are we allowing to vary over the simulation.

What are the levels and models we want to run?

```{r}
my_sim |> 
  add_fixed_effect(condition, ~ function(.x ) .25*time) |>
  add_random_effect(school >> student, ~ function(.x ) rnorm(1, sd = 1)) |> 
  add_random_effect(school, ~ function(.x ) rnorm(1, sd = 1)) |> 
  add_random_effect(district >> school, ~ function(.x ) rnorm(1, sd = 1)) |> 
  add_covariate() |> 
  add_error( ~ function(.x ) rnorm(1, sd = 1)) |>
  generate_response_var()
```





```{r}
f <- y ~ x > z

as.
```


```{r}
sim_samples_df |> 
  simulate_random_unit(student = rpois(n = n(), lambda = 10))
```





```{r}
condition_effect <- function(condition, condition_time){
  case_when(
    condition == "baseline" ~ 0,
    condition == "intervention" ~ .10)
}

sim_samples_df <- sim_samples_df |> 
  group_by(sim_sample, cohort, condition) |> 
  mutate(condition_time = time - min(time)) |> 
  ungroup() |> 
  mutate(
    .condition_effect = condition_effect(condition, condition_time)
  )
```


```{r}
sim_samples_df <- sim_samples_df |> 
  group_by(sim_sample, cohort) |> 
  mutate(.i_cohort = rnorm(n = 1, sd = 1)) |> 
  group_by(sim_sample, cohort, hospital) |> 
  mutate(.i_cohort_hospital = rnorm(n = 1, sd = 1)) |> 
  group_by(sim_sample, cohort, hospital, pcp) |> 
  mutate(.i_cohort_hospital_pcp = rnorm(n = 1, sd = 1)) |> 
  ungroup()

sim_samples_df
```

```{r}
sim_samples_df <- sim_samples_df |> 
  ungroup() |> 
  mutate(
    .error = rnorm(n = n(), sd = 1)
  )
```

```{r}
sim_samples_df <- sim_samples_df |> 
  ungroup() |> 
  mutate(
    .response = .condition_effect + .i_cohort + .i_cohort_hospital + 
      .i_cohort_hospital_pcp + .error) 
```

```{r}
library(lmerTest)

# cohort/hospital/pcp
# pcp/hospital/cohort

# fit <- lmer(.response ~ .condition_effect + (1 | cohort/hospital/pcp), data = df)
# summary(fit)

fit_df <- sim_samples_df |> 
  group_by(sim_sample) |> 
  nest() |> 
  mutate(
    fit = map(
      .x = data, 
      .f = ~ lmer(.response ~ condition*condition*time + (1 | cohort/hospital/pcp), data = .x)),
    results = map(fit, broom.mixed::tidy))

```

```{r}
power_df <- fit_df |> 
  ungroup() |> 
  unnest(results) |> 
  filter(term == "conditionintervention:time") |> 
  summarise(
    bias = mean(estimate - 1.25),
    power = mean(p.value < .05))

power_df
```




























